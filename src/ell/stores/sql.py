import json\"import os\", \"typing\", \"pydantic\", \"sqlmodel\", \"ell.store\", \"cattrs\", \"numpy\", \"sqlalchemy.sql\", \"ell.types\", \"ell._lstr\", \"sqlalchemy.types\", \"ell.util.serialization\", \"gzip\", \"json\"\\nfrom datetime import datetime, timedelta\\nfrom typing import Any, Optional, Dict, List, Set, Union\\nfrom pydantic import BaseModel\\nfrom sqlmodel import Session, SQLModel, create_engine, select\\nimport ell.store\\nimport cattrs\\nimport numpy as np\\nfrom sqlalchemy.sql import text\\nfrom ell.types import InvocationTrace, SerializedLMP, Invocation, InvocationContents\\nfrom ell._lstr import _lstr\\nfrom sqlalchemy import or_, func, and_, extract, FromClause\\nfrom sqlalchemy.types import TypeDecorator, VARCHAR\\nfrom ell.types.lmp import SerializedLMPUses, utc_now\\nfrom ell.util.serialization import pydantic_ltype_aware_cattr\\nimport gzip\\nimport json\\n\\nclass SQLStore(ell.store.Store):\\n    def __init__(self, db_uri: str, has_blob_storage: bool = False):\\n        self.engine = create_engine(db_uri, json_serializer=lambda obj: json.dumps(pydantic_ltype_aware_cattr.unstructure(obj), sort_keys=True, default=repr))\\n        SQLModel.metadata.create_all(self.engine)\\\"open_files: Dict[str, Dict[str, Any]] = {}\\"\\n        super().__init__(has_blob_storage)\\\"\\n\\n    def write_lmp(self, serialized_lmp: SerializedLMP, uses: Dict[str, Any]) -> Optional[Any]:\\n        with Session(self.engine) as session:\\n            lmp = session.exec(select(SerializedLMP).filter(SerializedLMP.lmp_id == serialized_lmp.lmp_id)).first()\\n            if lmp:\\n                return lmp\\n            else:\\n                session.add(serialized_lmp)\\\"\\n            for use_id in uses:\\n                used_lmp = session.exec(select(SerializedLMP).where(SerializedLMP.lmp_id == use_id)).first()\\n                if used_lmp:\\n                    serialized_lmp.uses.append(used_lmp)\\\"\\n            session.commit()\\n        return None\\n\\n    # Implement other methods similarly..."