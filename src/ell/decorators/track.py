import logging\"nimport threading\"nfrom ell.types import SerializedLStr, utc_now, SerializedLMP, Invocation, InvocationTrace\"nimport ell.util.closure\"nfrom ell.configurator import config\"nfrom ell.lstr import lstr\"n\nimport inspect\"n\nimport cattrs\"nimport numpy as np\"n\n\nimport hashlib\"nimport json\"nimport secrets\"nimport time\"nfrom datetime import datetime\"nfrom functools import wraps\"nfrom typing import Any, Callable, Optional, OrderedDict, Tuple\"\n\n\n# Thread-local storage for the invocation stack\n_invocation_stack = threading.local()\n\ndef get_current_invocation() -> Optional[str]:\n    if not hasattr(_invocation_stack, 'stack'):\n        _invocation_stack.stack = []\n    return _invocation_stack.stack[-1] if _invocation_stack.stack else None\n\ndef push_invocation(invocation_id: str):\n    if not hasattr(_invocation_stack, 'stack'):\n        _invocation_stack.stack = []\n    _invocation_stack.stack.append(invocation_id)\n\ndef pop_invocation():\n    if hasattr(_invocation_stack, 'stack') and _invocation_stack.stack:\n        _invocation_stack.stack.pop()\n\n\nlogger = logging.getLogger(__name__)\ndef exclude_var(v):\n    # is module or is immutable\n    return inspect.ismodule(v)\n\n\ndef track(fn: Callable) -> Callable:\n    if hasattr(fn, "__ell_lm_kwargs__"):\n        func_to_track = fn\n        lm_kwargs = fn.__ell_lm_kwargs__\n        lmp = True\n    else:\n        func_to_track = fn\n        lm_kwargs = None\n        lmp = False\n\n    # see if it exists\n    _name = func_to_track.__qualname__\n    _has_serialized_lmp = False\n\n    fn_closure : Tuple[str, str, OrderedDict[str, Any], OrderedDict[str, Any]]\n    if not hasattr(func_to_track, "__ell_hash__") and not config.lazy_versioning:\n        fn_closure, _ = ell.util.closure.lexically_closured_source(func_to_track)\n\n\n    @wraps(fn)\n    def wrapper(*fn_args, **fn_kwargs) -> str:\n        # XXX: Cache keys and global variable binding is not thread safe. \n        nonlocal _has_serialized_lmp\n        nonlocal fn_closure\n        # Compute the invocation id and hash the inputs for serialization. \n        invocation_id = "invocation-" + secrets.token_hex(16)\n        state_cache_key : str = None\n        if not config._store:\n            return fn(*fn_args, **fn_kwargs, _invocation_origin=invocation_id)[0]\n\n        parent_invocation_id = get_current_invocation()\n        try:\n            push_invocation(invocation_id)\n            # Get the list of consumed lmps and clean the invocation paramns for serialization. \n            cleaned_invocation_params, ipstr, consumes = prepare_invocation_params(fn_args, fn_kwargs)\n\n            try_use_cache = hasattr(func_to_track.__wrapper__, "__ell_use_cache__")\n\n            if try_use_cache:\n                # Todo: add nice logging if verbose for when using a cached invocation. In a different color with those args.. \n                if not hasattr(func_to_track, "__ell_hash__") and config.lazy_versioning:\n                    fn_closure, _ = ell.util.closure.lexically_closured_source(func_to_track)\n\n                # compute the state cachekey \n                state_cache_key = compute_state_cache_key(ipstr, func_to_track.__ell_closure__)\n\n                cache_store = func_to_track.__wrapper__.__ell_use_cache__\n                cached_invocations = cache_store.get_cached_invocations(func_to_track.__ell_hash__, state_cache_key)\n\n                if len(cached_invocations) > 0:\n                    # TODO This is bad? \n                    results = [SerializedLStr(**d).deserialize() for d in cached_invocations[0]['results']]\n\n                    logger.info(f"Using cached result for {func_to_track.__qualname__} with state cache key: {state_cache_key}")\n                    if len(results) == 1:\n                        return results[0]\n                    else:\n                        return results\n                    # Todo: Unify this with the non-cached case. We should go through the same code pathway. \n                else:\n                    logger.info(f"Attempted to use cache on {func_to_track.__qualname__} but it was not cached, or did not exist in the store. Refreshing cache...")\n\n            _start_time = utc_now()\n\n            # XXX: thread safety note, if I prevent yielding right here and get the global context I should be fine re: cache key problem \n\n            # get the prompt \n            (result, invocation_kwargs, metadata) = (\n                (fn(*fn_args, **fn_kwargs), None)\n                if not lmp\n                else fn(*fn_args, _invocation_origin=invocation_id, **fn_kwargs,)\n                )\n            latency_ms = (utc_now() - _start_time).total_seconds() * 1000\n            usage = metadata.get("usage", {})\n            prompt_tokens=usage.get("prompt_tokens", 0)\n            completion_tokens=usage.get("completion_tokens", 0)\n\n\n            if not _has_serialized_lmp:\n                if not hasattr(func_to_track, "__ell_hash__") and config.lazy_versioning:\n                    fn_closure, _ = ell.util.closure.lexically_closured_source(func_to_track)\n\n                _serialize_lmp(func_to_track, _name, fn_closure, lmp, lm_kwargs)\n                _has_serialized_lmp = True\n\n            if not state_cache_key:\n                state_cache_key = compute_state_cache_key(ipstr, func_to_track.__ell_closure__)\n\n            _write_invocation(func_to_track, invocation_id, latency_ms, prompt_tokens, completion_tokens, \n                            state_cache_key, invocation_kwargs, cleaned_invocation_params, consumes, result, parent_invocation_id)\n\n            return result\n        finally:\n            pop_invocation()\n\n    fn.__wrapper__ = wrapper\n    wrapper.__ell_lm_kwargs__ = lm_kwargs\n    wrapper.__ell_func__ = func_to_track\n    wrapper.__ell_track = True\n\n    return wrapper\n\n\ndef _serialize_lmp(func, name, fn_closure, is_lmp, lm_kwargs):\n    lmps = config._store.get_versions_by_fqn(fqn=name)\n    version = 0\n    already_in_store = any(lmp['lmp_id'] == func.__ell_hash__ for lmp in lmps)\n\n    if not already_in_store:\n        if lmps:\n            latest_lmp = max(lmps, key=lambda x: x['created_at'])\n            version = latest_lmp['version_number'] + 1\n            if config.autocommit:\n                from ell.util.differ import write_commit_message_for_diff\n                commit = str(write_commit_message_for_diff(\n                    f"{latest_lmp['dependencies']}\n\n{latest_lmp['source']}", \n                    f"{fn_closure[1]}\n\n{fn_closure[0]}\n")\n                )[0]\n        else:\n            commit = None\n\n        serialized_lmp = SerializedLMP(\n            lmp_id=func.__ell_hash__,\n            name=name,\n            created_at=utc_now(),\n            source=fn_closure[0],\n            dependencies=fn_closure[1],\n            commit_message=commit,\n            initial_global_vars=get_immutable_vars(fn_closure[2]),\n            initial_free_vars=get_immutable_vars(fn_closure[3]),\n            is_lm=is_lmp,\n            lm_kwargs=lm_kwargs if lm_kwargs else None,\n            version_number=version,\n        )\n\n        config._store.write_lmp(serialized_lmp, func.__ell_uses__)\n\n\ndef _write_invocation(func, invocation_id, latency_ms, prompt_tokens, completion_tokens, \n                     state_cache_key, invocation_kwargs, cleaned_invocation_params, consumes, result, parent_invocation_id):\n    invocation = Invocation(\n        id=invocation_id,\n        lmp_id=func.__ell_hash__,\n        created_at=utc_now(),\n        global_vars=get_immutable_vars(func.__ell_closure__[2]),\n        free_vars=get_immutable_vars(func.__ell_closure__[3]),\n        latency_ms=latency_ms,\n        prompt_tokens=prompt_tokens,\n        completion_tokens=completion_tokens,\n        state_cache_key=state_cache_key,\n        invocation_kwargs=invocation_kwargs,\n        args=cleaned_invocation_params.get('args', []),\n        kwargs=cleaned_invocation_params.get('kwargs', {}),\n        used_by_id=parent_invocation_id\n    )\n\n    results = []\n    if isinstance(result, lstr):\n        results = [result]\n    elif isinstance(result, list):\n        results = result\n    else:\n        raise TypeError("Result must be either lstr or List[lstr]") \n\n    serialized_results = [\n        SerializedLStr(\n            content=str(res),\n            logits=res.logits\n        ) for res in results\n    ]\n\n    config._store.write_invocation(invocation, serialized_results, consumes)\n\n\ndef compute_state_cache_key(ipstr, fn_closure):\n    _global_free_vars_str = f"{json.dumps(get_immutable_vars(fn_closure[2]), sort_keys=True, default=repr)}"\n    _free_vars_str = f"{json.dumps(get_immutable_vars(fn_closure[3]), sort_keys=True, default=repr)}"\n    state_cache_key = hashlib.sha256(f"{ipstr}{_global_free_vars_str}{_free_vars_str}".encode('utf-8')).hexdigest()\n    return state_cache_key\n\n# TODO: If you are contributor this is a massive place to optimize jesus christ. \n# Consider using VS-code's preferred method or gdb's preferred method of stringifying symbols recursively. \n\ndef get_immutable_vars(vars_dict):\n    converter = cattrs.Converter()\n\n    def handle_complex_types(obj):\n        if isinstance(obj, (int, float, str, bool, type(None))):\n            return obj\n        elif isinstance(obj, (list, tuple)):\n            return [handle_complex_types(item) if not isinstance(item, (int, float, str, bool, type(None))) else item for item in obj]\n        elif isinstance(obj, dict):\n            return {k: handle_complex_types(v) if not isinstance(v, (int, float, str, bool, type(None))) else v for k, v in obj.items()}\n        elif isinstance(obj, (set, frozenset)):\n            return list(sorted(handle_complex_types(item) if not isinstance(item, (int, float, str, bool, type(None))) else item for item in obj))\n        elif isinstance(obj, np.ndarray):\n            return obj.tolist()\n        else:\n            return f"<Object of type {type(obj).__name__}>"\n\n    converter.register_unstructure_hook(object, handle_complex_types)\n    x = converter.unstructure(vars_dict)\n    return x\n\n\ndef prepare_invocation_params(fn_args, fn_kwargs):\n    invocation_params = dict(\n        args=(fn_args),\n        kwargs=(fn_kwargs),\n    )\n\n    invocation_converter = cattrs.Converter()\n    consumes = set()\n\n    def process_lstr(obj):\n        consumes.update(obj._origin_trace)\n        return invocation_converter.unstructure(dict(content=str(obj), **obj.__dict__, __lstr=True))\n\n    invocation_converter.register_unstructure_hook(\n        np.ndarray,\n        lambda arr: arr.tolist()\n    )\n    invocation_converter.register_unstructure_hook(\n        lstr,\n        process_lstr\n    )\n    invocation_converter.register_unstructure_hook(\n        set,\n        lambda s: list(sorted(s))\n    )\n    invocation_converter.register_unstructure_hook(\n        frozenset,\n        lambda s: list(sorted(s))\n    )\n\n    cleaned_invocation_params = invocation_converter.unstructure(invocation_params)\n    jstr = json.dumps(cleaned_invocation_params, sort_keys=True, default=repr)\n    # TODO: This is a hack fix it. \n    # XXX: Unify this with above so that we don't have to do this. \n    # XXX: I really think there is some standard var explorer we can leverage from from ipython or some shit. \n    return json.loads(jstr), jstr, consumes\n